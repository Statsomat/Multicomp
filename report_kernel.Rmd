---
title: "Multiple Comparison Procedures To A Control"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment='', message = FALSE, error = TRUE, warning=FALSE, fig.width=8)
# Import libraries used further below
library(knitr) # for tables
library(kableExtra) # for tables 
library(multcomp) # mcp
library(sandwich) # sandwich
library(car) # type III Anova tests, levene
library(psych) # multi.hist
library(formula.tools) # for formula lhs
library(PerformanceAnalytics) # Scatterplot
library(rlang) # as_string for cast
library(stringr) # for strings
library(tibble) # for rownames to columns
library(HH) # hovplot 
library(onewaytests) #bf test
library(broom) # display with glance
```


```{r getdata}
# Initialize evaluation of chunks
eval0 <- FALSE
eval <- FALSE
eval_model <- FALSE
eval_model2 <- FALSE
eval_model3 <- FALSE
eval_model4 <- FALSE
eval_rows <- FALSE
oneway <- FALSE
sway <- FALSE
bftest <- FALSE 
homogtest <- FALSE
evallevene <- FALSE

# Apply selection of variables 
tryCatch({
  
  # Get data
  df <- params$data
  
  # Save a copy
  df_code <- df
  
  # Extract variables to keep 
  terms <- terms.formula(as.formula(params$model)) 
  terms2 <- rownames(attr(terms,"factors"))
  
  # Restrict df to variables from the formula
  df <- df[,terms2,drop=FALSE]
  
  # Save a copy
  df2 <- df
  
  # Initialize next computations
  eval0 <- TRUE
   
}, error=function(e) {
  
  stop(safeError("The model function seems to be wrong. We cannot prepare the dataset. "))
})

```


```{r prep, eval=eval0}
# Basic data preparation
tryCatch({
  
# Drop columns if all observations are missing 
col_names_missing <- sapply(df, function(col) all(is.na(col)))
df[ ,col_names_missing] <- list(NULL)
df_list <- df 
# Drop empty rows
rowsums <- data.frame(sapply(df,is.na))
if (length(which(rowSums(rowsums) == dim(df)[2])) != 0L){
  eval_rows <- TRUE
  rows_drop <- (which(rowSums(rowsums) == dim(df)[2]))
  length_non_complete <- length(which(rowSums(rowsums) == dim(df)[2]))
  df <- df[-rows_drop, ,drop=FALSE]
}
# Convert logical variables to character
cols_logical <- sapply(df, function(col) is.logical(col))
df[ ,cols_logical] <- sapply(df[ ,cols_logical], as.character)
# Convert numerical variables with less than 7 unique values to character (missing values omitted)
col_names_numeric <- sapply(df, function(col) length(unique(na.omit(col))) < 7L & is.numeric(col))
df[ ,col_names_numeric] <- sapply(df[ ,col_names_numeric], as.character)
# Extract numerical variables 
df_num <- df[which(sapply(df, is.numeric) == 1L)]
# Extract approximate continuous variables and non-continuous var
if (ncol(df_num)>0){
  rateunique_df <- sapply(df_num, function(col) continuous(col))
  
  if (params$cont_crit == "Severe"){
    df_cont <- df_num[,rateunique_df,drop=FALSE] # numeric, continuous resp. assumption fulfilled 
    df_noncont <- df_num[,!rateunique_df,drop=FALSE] # numeric, non-continuous 
  } else {
    df_cont <- df_num 
  }
  
   cols_continuous <- colnames(df_cont)
  
} 
# Extract character variables 
df_factor <- df[which(sapply(df, is.character) == 1L)]
# Categorical 
if (exists("df_noncont")){
  df_cat <- merge(df_factor, df_noncont, by="row.names")
  df_cat$Row.names <- NULL
  df_cat$Row.names.y <- NULL
} else {
  df_cat <- df_factor
}
# Initialize next computations
eval <- TRUE
}, error=function(e) {
  
  stop(safeError("The dataset cannot be prepared. "))
  
}
)
```


```{r basic, results="asis", eval=eval}
# Chunk with first page of basic information
cat("\n# Basic Information", fill=TRUE)
cat("\\small ", fill=TRUE)
cat("Automatic statistics for the file:", fill=TRUE)
dataname <- params$filename[1]
kable(dataname, col.names = "File", linesep = '', longtable=T) 
cat("Your selection for the encoding:", fill=TRUE)
if (params$fencoding=="unknown"){
  cat("Auto")
} else {cat("UTF-8")}
cat("\\newline",fill=TRUE) 
cat("Your selection for the decimal character:", fill=TRUE)
if (params$decimal=="auto"){
  cat("Auto")
} else {cat(params$decimal)}
cat("\\newline",fill=TRUE) 
  
cat("Observations (rows with at least one non-missing value): ", fill=TRUE)
cat(dim(df)[1])
cat("\\newline",fill=TRUE) 
# Missing rows
if (exists("length_non_complete")){
  cat("Number of rows that are dropped because they contain no values (all values are missing):", length_non_complete)
  cat("\\newline",fill=TRUE) 
}
cat("Variables (columns with at least one non-missing value): ", fill=TRUE)
cat(dim(df_list)[2])
cat("\\newline",fill=TRUE) 
# Missing columns
if (exists("col_names_missing")){
  if (sum(col_names_missing) != 0L){
    cat("Number of columns that are dropped because they contain no values (all values are missing):", sum(col_names_missing), fill=TRUE)
    cat("\\newline",fill=TRUE) 
  } 
}
if (exists("df_cont")){
  cat("Variables considered continuous: ", fill=TRUE)
  if (ncol(df_cont)>0){
    cat(ncol(df_cont),fill=TRUE)
    knitr::kable(cols_continuous, col.names = "Variables considered continuous", linesep = '', longtable=T) %>%
      kable_styling(font_size = 8, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))
  } else {
    cat("0", fill=TRUE)
    cat("\\newline",fill=TRUE)
    cat("Error: There are no continuous variables of interest in the dataset. Execution stopped. ")
    eval <- FALSE
  }
}
if (exists("df_cat")){
  cat("Variables considered categorical: ", fill=TRUE)
  if (ncol(df_cat)>0){
    cat(ncol(df_cat),fill=TRUE)
    knitr::kable(colnames(df_cat), col.names = "Variables considered categorical", linesep = '', longtable=T) %>%
      kable_styling(font_size = 8, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))
  } else {
    cat("0", fill=TRUE)
    cat("\\newline",fill=TRUE) 
    cat("\\newline",fill=TRUE) 
    cat("Error: There are no factors in the dataset. Execution stopped. ")
    eval <- FALSE
  }
}
```


```{r falsechar, results="asis", eval=eval}
# Numeric falsly to char? 
check_reading <- function(col){
  numeric <- !is.na(as.numeric(col))
  return(sum(numeric)/sum(!is.na(col)))
}
df_char2 <- df2[which(sapply(df2, is.character) == 1L)]
numeric_percent <- sapply(df_char2, function(col) check_reading(col))
if (length(numeric_percent[(numeric_percent>0.9)]) != 0L){
  cat("**Warning: More than 90% of the values of these columns could be treated as numeric. Nevertheless, because of some values or the selected decimal character, the columns must be treated as discrete. Are all the values plausible? Please check the data once more before uploading! Column(s):**", names(numeric_percent[(numeric_percent>0.9)]), fill=TRUE)
}
```


\pagebreak

```{r modelinformation, eval = eval, results = "asis"}

# Save all model information into a vector 
modelsplit <- c(params$model, params$fact, params$ref, params$alternative)

# List model information
cat("# Model Information", fill=TRUE)
cat("You defined the following linear model:", fill=TRUE)
cat(modelsplit[1])
cat("\\newline",fill=TRUE)
cat("You are interested in the factor:", fill=TRUE)
cat(modelsplit[2])
cat("\\newline",fill=TRUE)
cat("You are interested in pairwise comparisons to the reference level (control):", fill=TRUE)
cat(modelsplit[3])
```


```{r factoring, eval=eval}
# Factorize categorical variables 
df_cat_factor <- lapply(df_cat, as.factor)
df_factorized <- cbind(df_cont, df_cat_factor)  
```



```{r missings, results="asis", eval=eval}
# Notice for missings (only <10% missings allowed, only complete cases treated)
# Missings  > 10%
complete_rate <- sapply(df_factorized, function(col) 1-(sum(is.na(col)) / dim(df)[1])) 
if (length(which(complete_rate < 0.90)) != 0L){
  cat("**Error: Execution stop because of limit on missing values. There exist continuous variables with more than 10% missing values. This app allows max 10% missing values per observed variable. Please reconsider your data before using this app. **")
  miss_var <- names(which(complete_rate < 0.90)) 
  eval <- FALSE
  knitr::kable(miss_var, col.names = "Variable(s) with more than 10% missing values", linesep = '', longtable = T) %>%
    kable_styling(position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))
}

if (nrow(as.data.frame(df_factorized[complete.cases(df_factorized),])) < 15){
  cat("**Error: Minimum 15 complete cases required. **")
  eval <- FALSE
}

# Restrict df to complete cases 
if (length(which(complete_rate < 1)) != 0L){
  df_factorized <- as.data.frame(df_factorized[complete.cases(df_factorized),])
  cat("Warning: There are missing values in the dataset. We will consider in what follows the analysis based on the complete cases. For a listing of the missing values, check the Statsomat/EDAR or Statsomat/EDAPY app for descriptive statistics of the dataset. ", fill=TRUE)
  }
```


```{r descplots, dev="cairo_pdf", eval=eval, results='asis'}

cat("# Descriptive Plots \n", fill=TRUE)
cat("\n \\small \n ", fill=TRUE)

tryCatch({

    cat("## Dependent Variable \n", fill=TRUE)
    #Histogram and Boxplot for DV
    modelfunction = as.formula(modelsplit[1])
    x <- unlist(df_factorized[which(colnames(df_factorized)==lhs(modelfunction))])
    x <- as.numeric(x)
    main = paste("Histogram of",lhs(modelfunction))
    ylab="Relative Frequency"
    xlab= as_string(lhs(modelfunction))
    freq=FALSE
    bcol="#2fa42d"
    dcol=c("#396e9f","#396e9f")
    dlty=c("dotted", "solid")
    breaks=21 
      
    h <- hist(x, plot=FALSE, breaks=breaks)
    m <- mean(x, na.rm=TRUE)
    s <- sd(x, na.rm=TRUE)
    d <- density(x, na.rm=TRUE)
    # Set nice x and y axis limits
    xlims <- pretty(c(floor(h$breaks[1]),ceiling(last(h$breaks))))
    ymax <- max(h$density)
    dmax <- max(d$y)
    ymax <- max(ymax,dmax)
    # Plots
    plot(h, freq=freq, ylim=c(0, ymax*1.2), ylab=ylab, xlab=xlab, main=main, col=bcol, xlim = c(min(xlims), max(xlims)))
    lines(d, lty=dlty[1], col=dcol[1])
    curve(dnorm(x,m,s), add=TRUE, lty=dlty[2], col=dcol[2])
    cat("\n \\newline \n ", fill=TRUE)
    boxplot(x, col = "#2fa42d", main = paste("Boxplot of",lhs(modelfunction)),
              xlab=paste(lhs(modelfunction)), horizontal = TRUE)

}, error=function(e) {
 cat("Error: This plot cannot be generated. ")
  }
)
```


```{r descplots2, dev="cairo_pdf", eval=eval, results='asis'}
tryCatch({
  
  cat("\n \\pagebreak \n",fill=TRUE)
  
  # Boxplot for categorical IV
  # Only if categorical on the rhs
  if(modelsplit[2] %in% colnames(df_cat)){
    cat("## Dependent Against Categorical Factors \n", fill=TRUE)
    for (i in 1:ncol(df_cat)) {
        boxplot(as.formula(paste(lhs(modelfunction), "~" , colnames(df_cat)[i])), data=df_factorized, col = "#2fa42d", main=paste("Boxplot of",paste(lhs(modelfunction), "~" , colnames(df_cat)[i])), horizontal = FALSE )
      cat("\n \\pagebreak \n",fill=TRUE)
    }
  }


}, error=function(e) {
  cat("Error: This plot cannot be generated. ")
  }
)
```

```{r descplots3, dev="cairo_pdf", eval=eval, results='asis'}
tryCatch({

cat("\n \\pagebreak \n",fill=TRUE)
# Scatterplot for numerical IV
df_cont_iv <- df_cont[which(colnames(df_cont)!=lhs(modelfunction))]
if (ncol(df_cont_iv)>0) {
  cat("## Dependent against Covariates \n", fill=TRUE)
  if (ncol(df_cont_iv)==1) {
   plot(x =  df_cont_iv[,1],y=x, col = "#2fa42d", main=paste0("Scatterplot of ", colnames(df_cont_iv))
        , xlab = colnames(df_cont_iv), ylab = lhs(modelfunction))
  }else if(ncol(df_cont_iv)>1){
    chart.Correlation(df_cont_iv, col = "#2fa42d", main=paste("Correlation Plot of numerical independent Variables"))
  }
}


}, error=function(e) {
  cat("Error: This plot cannot be generated. ")
  }
)
```

```{r descplots4, dev="cairo_pdf", eval=eval, results='asis'}
tryCatch({
  
  cat("\n \\pagebreak \n",fill=TRUE)
  # Interaction Plot
  if(ncol(df_cat)>=2){
    cat("## Interaction Plot for Factors \n", fill=TRUE)
    cat("\n Note: The more parallel the lines, the less likely is the significance of the interaction of the factors. \n", fill=TRUE)
    for (i in 1:(ncol(df_cat)-1)) {
      for (j in (i+1):ncol(df_cat)) {
        interaction.plot(df_cat[,i], df_cat[,j], x, xlab= colnames(df_cat)[i], trace.label = colnames(df_cat)[j], ylab=paste("mean of", lhs(modelfunction)), col = "#2fa42d",main=paste0("Interaction Plot of ", colnames(df_cat)[i], " and ", colnames(df_cat)[j]))
        cat("\n \\newline \n ", fill=TRUE)
      }
    }
  }
  
}, error=function(e) {
  cat("Error: This plot cannot be generated. ")
  }
)
```


```{r relevel, eval=eval}
# Relevel factor of interest 

tryCatch({
  
  factor_index <- which(colnames(df_factorized) == modelsplit[2])
  df_factorized[,factor_index] <- relevel(df_factorized[,factor_index], ref = modelsplit[3])

  ## Initialize next computations
  eval_model <- TRUE
  
}, error=function(e) {
  cat("Error: Model cannot be fit. There is a problem with the model function or with the data. Execution stopped. ")
  }
)
```


```{r fitmodel, eval = eval_model}
# Fit Linear Model

tryCatch({
  
  modelfunction <- modelsplit[1]
  lmfit <- lm(modelfunction, data = df_factorized)
  
  ## Initialize next computations
  eval_model2 <- TRUE
  
}, error=function(e) {
  
  stop(safeError("The model function could not be fitted to the data. "))
  
}
)
```

```{r Parametertable, dev="cairo_pdf", eval = eval_model2, results='asis'}

tryCatch({

  # Table Parameter estimates
  cat("\n \\pagebreak \n",fill=TRUE)
  cat("\n# Analysis of Variance  \n", fill=TRUE)
  
  coef.lmfit <- as.data.frame(summary(lmfit)$coefficients)
  coef.lmfit1 <- data.frame("Variable"=rownames(coef.lmfit),"Value"=coef.lmfit$Estimate, 
  
                            "Std.Error"=coef.lmfit$'Std. Error',"T.value"=coef.lmfit$'t value',
                            "P.value"=coef.lmfit$'Pr(>|t|)')
  
  # column significance levels
  coef.lmfit1$'sign. level' <- NA
  coef.lmfit1$'sign. level'[which(abs(coef.lmfit$'Pr(>|t|)') <= 0.001)] <- "***"
  coef.lmfit1$'sign. level'[which(abs(coef.lmfit$'Pr(>|t|)') > 0.001)] <- "**"
  coef.lmfit1$'sign. level'[which(abs(coef.lmfit$'Pr(>|t|)') > 0.01)] <- "*"
  coef.lmfit1$'sign. level'[which(abs(coef.lmfit$'Pr(>|t|)') > 0.05)] <- "."
  coef.lmfit1$'sign. level'[which(abs(coef.lmfit$'Pr(>|t|)') > 0.1)] <- " "
  coef.lmfit1$'sign. level'[which(is.na(coef.lmfit1$'P.value'))] <- "-"
  
  names(coef.lmfit1)[6] <- paste0(names(coef.lmfit1)[6], footnote_marker_number(1, "latex"))
 
  
  # column declaration of significance
  coef.lmfit1$sig <- NA  
  for (i in 2:nrow(coef.lmfit1)) {
    pvalue <- round(as.numeric(coef.lmfit1[i,]$'P.value'),3)
    if(pvalue <= 0.05){
      if(str_detect(coef.lmfit1[i,]$Variable, ":")==T){
        coef.lmfit1[i,]$sig <- paste0("Interaction effect if level(s) ", sub(":", paste0(" and "), coef.lmfit1[i,]$Variable)," are present is significant. ")
                                
      }else coef.lmfit1[i,]$sig <- paste0("Significant difference between ", 
                                          coef.lmfit1[i,]$Variable, " and the reference of this factor. ")
    }else{ 
      if(str_detect(coef.lmfit1[i,]$Variable, ":")==T){
        coef.lmfit1[i,]$sig <- paste0("Interaction effect if level(s) ",sub(":", paste0(" and "), coef.lmfit1[i,]$Variable)," are present is not significant. ")
      }else coef.lmfit1[i,]$sig <- paste0("No significant difference between ",coef.lmfit1[i,]$Variable, " and the reference of this factor.")}
       
  }
   
  
  pvalue <- round(as.numeric(coef.lmfit1[1,]$'P.value'),3)
  if(pvalue <= 0.05){
    coef.lmfit1[1,]$sig <- "Intercept statistically significant."
  } else {coef.lmfit1[1,]$sig <- "Intercept not statistically significant."}
  
  # Set format to pvalue column 
  coef.lmfit1$'P.value' <- sapply(coef.lmfit1$'P.value',pformat)

  # footnote significance codes
  names(coef.lmfit1)[7] <- "Significance at 5 percent error"
  fn1 <- "'***': sign. to 0.1% error. '**': sign. to 1% error. '*': sign. to 5% error. ' . ': sign. to 10% error. '     ': not sign. ' - ': no statement."
  number = fn1

  ## Initialize next computations
  eval_model3 <- TRUE
  
}, error=function(e) {
  
  stop(safeError("The model function could not be fitted to the data. "))
  
}
)
```

```{r Parametertable2, dev="cairo_pdf", eval = eval_model3, results='asis'}  
# Output Table
cat("## Detailed Influence of Predictors (Linear Model Parameter Estimates) \n", fill=TRUE)
cat("Note: No adjustement for multiplicity. Interpretation in the last column suitable especially to categorical predictors. ", fill=TRUE)
opts <- options(knitr.kable.NA = "")
x <- knitr::kable(coef.lmfit1, digits=2, escape = F, linesep = '', caption=cat(" ", fill=TRUE), longtable = T)
footnote(x, number = number) %>%
  kable_styling(x, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))
```

```{r effectcoding, eval = eval_model3}
# Set effect coding for the rest of the factors, relevant for the type III Anova table 
for (i in 1:ncol(df_factorized)) {
  if (is.factor(df_factorized[,i])==T) contrasts(df_factorized[,i]) <- contr.sum
}
```

```{r type3, dev="cairo_pdf", eval=eval_model3, results='asis'}
# Type III tests 
tryCatch({

  a = Anova(lmfit, type=3)
  #Create dataframe
  df_table <- data.frame("Variable"=rownames(a),"Sum.Sq"=a$`Sum Sq`,"Df"=a$Df,"F.value"=a$`F value`,"P.value"=a$'Pr(>F)')
  #add a new column Interpretation
  df_table$'Interpretation (5% error)' <- NA
  #label intercept line
  if(df_table[1,'P.value']<=0.05){
    df_table[1,'Interpretation (5% error)']='Intercept statistically significantly different from zero.'
  }else{df_table[1,'Interpretation (5% error)']='Intercept not statistically significantly different from zero.'}
  
  #make entries dependent on p-value
  for(i in 2:nrow(df_table)){
    pvalue <- round(as.numeric(df_table[i,'P.value']),3)
    ifelse(pvalue<=0.05,
           if(str_detect(df_table[i,'Variable'], ":")){
             df_table[i,'Interpretation (5% error)'] <- paste0("This interaction is statistically significant. ")
           } else {
             df_table[i,'Interpretation (5% error)'] <- paste0("The predictor ", df_table[i,'Variable'], " is statistically significant. ")},
           
           if(str_detect(df_table[i,'Variable'], ":")){
             df_table[i,'Interpretation (5% error)'] <- paste0("This interaction is not statistically significant. ")
           } else {
             df_table[i,'Interpretation (5% error)'] <- paste0("The predictor ", df_table[i,'Variable'], " is not statistically significant. ")
           }
        )
  }
  
  # Format p-value column to p-value
  df_table$P.value <- sapply(df_table$P.value,pformat)

  # Next chunks 
  eval_model4 <- TRUE 

}, error=function(e) {
  
  stop(safeError("ANOVA Type III table cannot be generated. Are there any empty cells in the data? Execution stopped. "))
  
})
```


```{r anovatypeiiitable, dev="cairo_pdf", eval = eval_model4, results='asis'}
#plot result including heading
cat("## Total Influence of Predictors (ANOVA Type III) \n", fill=TRUE)
options(knitr.kable.NA = '')
knitr::kable(df_table, digits=2, escape = T, linesep = '', caption=cat(" ", fill=TRUE), longtable = T) %>%
  kable_styling(position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header")) %>%
  footnote(general = "If any, a significant interaction means the main effect of one in the interaction involved predictor depends on (the levels of) the other predictor.")   
  
```


```{r GoodnessOfFit, dev="cairo_pdf", eval = eval_model4, results='asis'}
sum.lmfit <- summary(lmfit)

GoF <- data.frame('Values'=c('Multiple R-Squared'= sum.lmfit$r.squared,
                             'Adjusted R-Squared'= sum.lmfit$adj.r.squared,
                             'F-statistic'= sum.lmfit$fstatistic[1],'P'= glance(lmfit)$p.value))

GoF$Explanation <- c("Fraction of variance explained by the model.", 
                     "R-Squared plus penalizes the number of predictors.", 
                     "Measure for the overall significance of the model.", 
                     "Hypothesis test of the overall significance of the model.")

GoF$Interpretation <- NA
GoF$Interpretation[1] <- "0: No fitting of data by the model. , 1: Perfect fit." 
GoF$Interpretation[2] <-"A higher value means a better fit by the model."
GoF$Interpretation[3] <-"Check the P-value to assess significance."

if (GoF$Values[4] < 0.05){
  GoF$Interpretation[4] <- "Significance at 5% error. The model is better than the only-intercept model."
  } else {
  GoF$Interpretation[4] <- "No significance at 5% error. The model is not better than the only-intercept model."
  }

GoF$Values[4] <- pformat(GoF$Values[4])
GoF$Values[1:3] <- round(as.numeric(GoF$Values[1:3]),digits = 2)

cat("## Goodness Of Fit Measures \n", fill=TRUE)
cat("To evaluate the model, some parameters are listed below.  \n", fill=TRUE)

options(knitr.kable.NA = '')
x1 <- knitr::kable(GoF, digits=3, escape = T, linesep = '', caption=cat(" ", fill=TRUE), longtable = T)
kable_styling(x1, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))

```

```{r diagnosticplots, dev="cairo_pdf", eval=eval_model4, results="asis"}
cat("# Diagnostics", fill=TRUE) 
cat("## Diagnostic Plots ", fill=TRUE) 
layout(matrix(c(1,2,3,4),2,2)) 
plot(lmfit) 
```

```{r def_control_homog, eval = eval_model4}
# Define execution especially for a one-way model 
oneway <- as.logical(eval_model4*(length(df_cat_factor)==1L))
sway <- as.logical(eval_model4*(length(df_cat_factor)>1L))
```


```{r titlevariances, dev="cairo_pdf", eval = eval_model4,  results="asis"}
cat("\\pagebreak ", fill=TRUE)
# Homogeneity of Variances
cat("##  Homogeneity of Variances", fill=TRUE)
## Alpha for the homogeneity tests 
alphahomog <- 0.1
```

```{r browntest0, dev="cairo_pdf", eval = oneway, results="asis"}
# Title Brown and Forsyth Test
cat("###  Brown and Forsyth Test of Homogeneity of Variances", fill=TRUE)
```

```{r browntest, dev="cairo_pdf", eval = oneway}
tryCatch({
  bf <- hov(as.formula(modelfunction), data = df_factorized)
  bftest <- TRUE 
   }, error = function(e) {cat("")}
  )
```

```{r browntest2, dev="cairo_pdf", eval = bftest}
hov(as.formula(modelfunction), data = df_factorized)
```

```{r browntest3, dev="cairo_pdf", eval = bftest, results="asis"}
if (bf$p.value <= alphahomog) {
   cat("Warning: Group variances significantly heterogeneous at 10% type I error. Hypothesis tests from the Analysis of Variance chapter may not be valid. We recommend in this case the consideration of the subsequent Dunnet tests based on the Sandwich estimator. ", fill=TRUE)
} else {
   cat("Notice: We assume that the group variances are homogeneous. ", fill=TRUE)
   homogtest <- TRUE
}
```

```{r browntest4, dev="cairo_pdf", eval = bftest, results="asis", fig.width=8, fig.cap="Homogeneity of Variance Plot"}
# Brown and Forsythe Plot
cat("### Brown and Forsyth Plot", fill=TRUE)
hovPlot(as.formula(modelfunction), data = df_factorized)
cat("\\newline ", fill=TRUE)
cat("Interpretation: The response variable is denoted by y. The fist of the three plots contains boxplots of each level of the independent variable. In the second plot, the response variable y is centered by its median, such that the median of the transformation equals 0. In the third plot, the absolute deviations from the median of the response y are shown. The Brown and Forsyth test statistic is the F statistic resulting from an ordinary one-way analysis of variance on the data points in the third panel (on the absolute deviations from the median). ", fill=TRUE)
```
 
```{r levene, eval = sway, results="asis"}
cat("### Levene Test of Homogeneity of Variances ", fill=TRUE)
```

```{r levene2, eval = sway}
tryCatch({
  
  leveneobj <- leveneTest(as.formula(modelfunction), data = df_factorized)
  evallevene <- TRUE
  
}, error = function(e) {e})
```


```{r levene3, eval = evallevene}
 leveneTest(as.formula(modelfunction), data = df_factorized)
```


```{r levene4, dev = "cairo_pdf", eval = evallevene, results="asis"}
if (leveneobj$`Pr(>F)`[1] <= alphahomog) {
    cat("Warning: Group variances significantly heterogeneous at 10% type I error. Hypothesis tests from the Analysis of Variance chapter may not be valid. We recommend in this case the consideration of the subsequent Dunnet tests based on the Sandwich estimator. ", fill=TRUE)
} else {
   cat("Notice: We assume that the group variances are homogeneous. ", fill=TRUE)
   homogtest <- TRUE
}
```

\pagebreak

```{r Dunnet, eval = eval_model4, results='asis', dev="cairo_pdf"}
cat("\n# Multiple Comparisons of Means to a Control \n", fill=TRUE)
#cat("\\small ", fill=TRUE)
cat("Theoretical background: Testing multiple hypotheses simultaneously and each at the same pre-specified significance level, increases the probability of false positive effects. The probability to commit at least one false positive decision increases with the number of hypotheses. A solution to overcome this problem is given by multiple comparisons procedures. Here, we do not control the per-hypothesis Type I error but the probability of committing at least one Type I error over all hypotheses. Using p-values adjusted for multiplicity, individual hypotheses can be finally compared with the pre-specified significance level.",fill=TRUE)

cat("\n## Dunnet \n", fill=TRUE)

# MCPs with a control Dunnet
## Construct input to mcp2 function which is an update of the original mcp function 

key <- modelsplit[2] 
factorlevel <- modelsplit [3]
lev <- levels(df_factorized[,colnames(df_factorized)==key])
side <- modelsplit[4]

if(side=="less"){
  symb <- ">="
  sidetext <- side
  }
if(side=="greater"){
  symb <- "<="
  sidetext <- side
  }
if(side=="two.sided"){
  symb <- "="
  sidetext <- "different"}

#Description above
cat("\\begin{center} Multiple Comparison: Dunnet Contrasts \\end{center}", fill=TRUE)
if(side == "two.sided"){
  cat(paste("Test whether the factor level ", factorlevel, " of the factor ", key, " is different from the other levels. The Null Hypothesis is for example ", lev[2],"-",factorlevel,"=0."))  
}else{
  cat(paste("Test whether the factor level ", factorlevel, " of the factor ", key, " is ", side, " than the other levels. The Null Hypothesis is for example ", lev[2],"-",factorlevel,symb,"0." ), fill=TRUE)
}

#compute multiple comparison
mylist <- list()
mylist[[key]] <- "Dunnet"
names(mylist) <- key 

output_mcp <- glht(lmfit, linfct = mcp2(mylist), alternative = side) 
summcp<- summary(output_mcp)

#pretty table
glht_dunnet <- data.frame("Value"=summcp$test$coefficients, 
                          "Std.Error"= summcp$test$sigma, "T-value"=summcp$test$tstat,
                          "P.value"= as.numeric(summcp$test$pvalues))

rownames(glht_dunnet) <- paste(rownames(glht_dunnet),symb,"0")

glht_dunnet$'Sign. level' <- NA
glht_dunnet$'Sign. level'[which(abs(glht_dunnet$P.value ) <= 0.001)] <- "***"
glht_dunnet$'Sign. level'[which(abs(glht_dunnet$P.value) > 0.001)] <- "**"
glht_dunnet$'Sign. level'[which(abs(glht_dunnet$P.value) > 0.01)] <- "*"
glht_dunnet$'Sign. level'[which(abs(glht_dunnet$P.value) > 0.05)] <- "."
glht_dunnet$'Sign. level'[which(abs(glht_dunnet$P.value) > 0.1)] <- " "
glht_dunnet$'Sign. level'[which(is.na(glht_dunnet$P.value))] <- "-"

glht_dunnet$P.value <- sapply(glht_dunnet$P.value,pformat)

names(glht_dunnet)[5] <- paste0(names(glht_dunnet)[5], footnote_marker_number(1, "latex"))

#Interpretation

glht_dunnet$sig <- NA
if(side != "two.sided"){
  for (i in 1:nrow(glht_dunnet)) {
    if(glht_dunnet[i,]$P.value <= 0.05){
      glht_dunnet[i,]$sig <- paste0("Significant. Level ", lev[i+1], " of factor ", key, " is significantly ", side, " than ", factorlevel, footnote_marker_number(3, "latex"))
    }else{ 
      glht_dunnet[i,]$sig <- paste0("Not Significant. Level ", factorlevel, " of factor ", key , " is ", side, " than " , lev[i+1], footnote_marker_number(2, "latex"))}
  }
}else{
    for (i in 1:nrow(glht_dunnet)) {
    if(glht_dunnet[i,]$P.value <= 0.05){
      glht_dunnet[i,]$sig <- paste0("Significant. Level ", lev[i+1], " of factor ", key, " is significantly different from ", factorlevel, footnote_marker_number(3, "latex"))
    }else{ 
      glht_dunnet[i,]$sig <- paste0("Not Significant. Level ", factorlevel, " of factor ", key , " is not different from " , lev[i+1], footnote_marker_number(2, "latex"))}
  }
}

# footnote significance codes
names(glht_dunnet)[6] <- "Significance at 5 percent Type I error"
fn1 <- "'***': sign. to 0.1% error. '**': sign. to 1% error. '*': sign. to 5% error. ' . ': sign. to 10% error. '     ': not sign. ' - ': no statement."
fn2 <- "H1 does not hold significantly."
fn3 <-  "H1 holds significantly."
number= c(fn1, fn2, fn3)

#rownames to column 
colnames(glht_dunnet)[4] <- c("adjusted P.value")
glht_dunnet <- rownames_to_column(glht_dunnet, var="Null Hypothesis") %>% head

#Output table
opts <- options(knitr.kable.NA = "")
x <- knitr::kable(glht_dunnet, digits=2, escape = F, linesep = '', caption=cat(" ",fill=TRUE), longtable = T)
footnote(x, number = number) %>%
  kable_styling(x, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))

#simoultanous confidence intervals 
cat("\\begin{center} Simoultaneous Confidence Intervals: Dunnet Contrasts \\end{center}",fill=TRUE)
cat(paste("Simultaneous Confidence Intervals which includes the true value of the difference between the reference level ", factorlevel, " and the other levels of ", key), fill=TRUE)

confmcp <- confint(output_mcp, level = 0.95) 
conf_glht <- as.data.frame(confmcp$confint)
colnames(conf_glht) <- c("Value", "Lower bound", "Upper bound")
rownames(conf_glht) <- paste(rownames(conf_glht),symb,"0")

conf_glht$sig <- NA
for (i in 1:nrow(conf_glht)) {
  if(sign(conf_glht$`Lower bound`)[i]==sign(conf_glht$`Upper bound`)[i]){
    conf_glht[i,]$sig <- paste0("The interval (", round(conf_glht$`Lower bound`[i],2), ", ", round(conf_glht$`Upper bound`[i],2), ") traps the true difference ", lev[i+1], "-", factorlevel, " with probability 95 percent.", footnote_marker_number(1, "latex") )
  }else{ 
    conf_glht[i,]$sig <- paste0("The interval (", round(conf_glht$`Lower bound`[i],2), ", ", round(conf_glht$`Upper bound`[i],2), ") traps the true difference ", lev[i+1], "-", factorlevel, " with probability 95 percent.", footnote_marker_number(2, "latex"))}
}

fn4 <- "Remark: Zero is not in the confidence interval."
fn5 <- "Remark: Zero is in the confidence interval."
number_2= c(fn4, fn5)

colnames(conf_glht)[4] <- "Interpretation"
conf_glht <- rownames_to_column(conf_glht, var="Null Hypothesis") %>% head

opts <- options(knitr.kable.NA = "")

x <- knitr::kable(conf_glht, digits=2, escape = F, linesep = '', caption=cat(" ",fill=TRUE), longtable = T)
footnote(x, number = number_2) %>% 
  kable_styling(x, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))

```

\pagebreak

```{r dunnet_stepdown, dev = "cairo_pdf", eval = eval_model4, results = "asis"}
# MCPs with a control Dunnet step-down 
cat("## Dunnet Step-Down \n", fill=TRUE)
cat("Note: The step-down procedure may lead to more powerful hypotheses tests and may be be applied for hypotheses satisfying the free combination condition, as in our many-to-one case. ", fill=TRUE)
mylist <- list()
mylist[[key]] <- "Dunnet"
names(mylist) <- key 
output_mcp <- glht(lmfit, linfct = mcp2(mylist), alternative = side) 
summcp<- summary(output_mcp, test = adjusted(type = "free"))
#pretty table
glht_dunnet <- data.frame("Value"=summcp$test$coefficients, 
                          "Std.Error"= summcp$test$sigma, "T-value"=summcp$test$tstat,
                          "P.value"= as.numeric(summcp$test$pvalues))
rownames(glht_dunnet) <- paste(rownames(glht_dunnet),symb,"0")
glht_dunnet$'Sign. level' <- NA
glht_dunnet$'Sign. level'[which(abs(glht_dunnet$P.value ) <= 0.001)] <- "***"
glht_dunnet$'Sign. level'[which(abs(glht_dunnet$P.value) > 0.001)] <- "**"
glht_dunnet$'Sign. level'[which(abs(glht_dunnet$P.value) > 0.01)] <- "*"
glht_dunnet$'Sign. level'[which(abs(glht_dunnet$P.value) > 0.05)] <- "."
glht_dunnet$'Sign. level'[which(abs(glht_dunnet$P.value) > 0.1)] <- " "
glht_dunnet$'Sign. level'[which(is.na(glht_dunnet$P.value))] <- "-"
glht_dunnet$P.value <- sapply(glht_dunnet$P.value,pformat)
names(glht_dunnet)[5] <- paste0(names(glht_dunnet)[5], footnote_marker_number(1, "latex"))
#Interpretation
#TODO Interpretation Dunnet anpassen nach H1
glht_dunnet$sig <- NA
for (i in 1:nrow(glht_dunnet)) {
  if(glht_dunnet[i,]$P.value <= 0.05){
    glht_dunnet[i,]$sig <- paste0("Significant. Level ", lev[i+1], " of factor ", key, " is significantly ", sidetext, " than ", factorlevel, footnote_marker_number(3, "latex"))
  }else{ 
    glht_dunnet[i,]$sig <- paste0("Not Significant. Level ", factorlevel, " of factor ", key , " is not ", sidetext, " than " , lev[i+1], footnote_marker_number(2, "latex"))}
}
# footnote significance codes
names(glht_dunnet)[6] <- "Significance at 5 percent Type I error"
fn1 <- "'***': sign. to 0.1% error. '**': sign. to 1% error. '*': sign. to 5% error. ' . ': sign. to 10% error. '     ': not sign. ' - ': no statement."
fn2 <- "H1 does not hold significantly."
fn3 <-  "H1 holds significantly."
number= c(fn1, fn2, fn3)
#rownames to column 
glht_dunnet <- rownames_to_column(glht_dunnet, var="Null Hypothesis") %>% head
#Output table
opts <- options(knitr.kable.NA = "")
x <- knitr::kable(glht_dunnet, digits=2, escape = F, linesep = '', caption="Multiple Comparison: Dunnet Contrasts", longtable = T)
footnote(x, number = number) %>%
  kable_styling(x, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))
```

\pagebreak 

```{r dunnet_sandwich, dev = "cairo_pdf", eval = eval_model4, results = "asis"}
# MCPs with a control Dunnet Sandwich

key <- modelsplit[2] 
factorlevel <- modelsplit [3]
lev <- levels(df_factorized[,colnames(df_factorized)==key])
side <- modelsplit[4]
if(side=="less"){symb <- ">="}
if(side=="greater"){symb <- "<="}
if(side=="two.sided"){symb <- "="}

cat("## Dunnet Sandwich ", fill=TRUE)
cat("\nThe sandwich function provides a heteroskedasticity-consistent estimate of the covariance matrix. Thus, the sandwich estimate is resistant to the violation of the variance homogeneity assumption.\n", fill=TRUE)
cat("\\begin{center} Multiple Comparison: Dunnett Contrasts Sandwich \\end{center}", fill=TRUE)

#Description above
if(side == "two.sided"){
  cat(paste("\nTest whether the factor level ", factorlevel, " of the factor ", key, " is different from the other levels. The Null Hypothesis is for example ", lev[2],"-",factorlevel,"=0."))  
}else{
  cat(paste("\nTest whether the factor level ", factorlevel, " of the factor ", key, " is ", side, " than the other levels. The Null Hypothesis is for example ", lev[2],"-",factorlevel,symb,"0." ), fill=TRUE)
}

# MCPs with a control Dunnet Sandwich
output_sandwich <- glht(lmfit, linfct = mcp2(mylist), alternative = side, vcov = sandwich)
sum.sandw <- summary(output_sandwich)

sandw.df <- data.frame("Value"=sum.sandw$test$coefficients, 
                          "Std.Error"= sum.sandw$test$sigma, "T-value"=sum.sandw$test$tstat,
                          "P.value"= as.numeric(sum.sandw$test$pvalues))
rownames(sandw.df) <- paste(rownames(sandw.df),symb,"0")




sandw.df$'Sign. level' <- NA
sandw.df$'Sign. level'[which(abs(sandw.df$'P.value') <= 0.001)] <- "***"
sandw.df$'Sign. level'[which(abs(sandw.df$'P.value') > 0.001)] <- "**"
sandw.df$'Sign. level'[which(abs(sandw.df$'P.value') > 0.01)] <- "*"
sandw.df$'Sign. level'[which(abs(sandw.df$'P.value') > 0.05)] <- "."
sandw.df$'Sign. level'[which(abs(sandw.df$'P.value') > 0.1)] <- " "

sandw.df$'Sign. level'[which(is.na(sandw.df$'P.value'))] <- "-"

names(sandw.df)[5] <- paste0(names(sandw.df)[5], footnote_marker_number(2, "latex"))


#Interpretation
sandw.df$sig <- NA
for (i in 1:nrow(sandw.df)) {
  if(sandw.df[i,]$P.value <= 0.05){
    sandw.df[i,]$sig <- paste0("Significant. Level ", lev[i+1], " of factor ", key, " is significantly ", sidetext, " than ", factorlevel, footnote_marker_number(4, "latex"))
  }else{ 
    sandw.df[i,]$sig <- paste0("Not Significant. Level ", factorlevel, " of factor ", key , " is not ", sidetext, " than " , lev[i+1], footnote_marker_number(3, "latex"))}
}

sandw.df$'P.value' <- sapply(sandw.df$'P.value',pformat)

names(sandw.df)[4] <- paste0("adjusted ", names(sandw.df)[4])
names(sandw.df)[6] <- "Significance at 5 percent Type I error"

# footnote significance codes
fn1 <- "Note: Due to the applied sandwich estimator, the standard errors of the effects may be unequal."
fn2 <- "'***': sign. to 0.1% error. '**': sign. to 1% error. '*': sign. to 5% error. ' . ': sign. to 10% error. '     ': not sign. ' - ': no statement."
fn3 <- "H1 does not hold significantly."
fn4 <-  "H1 holds significantly."
number= c(fn1, fn2, fn3, fn4)

sandw.df <- rownames_to_column(sandw.df, var="Null Hypothesis") %>% head

x1 <- knitr::kable(sandw.df , digits=3, escape = F, linesep = '', caption=cat(" ", fill=TRUE), longtable = T)
footnote(x1, number = number) %>%
  kable_styling(x1, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))


sandw.ki <- confint(output_sandwich, level = 0.95)
sandw.ki.df <- as.data.frame(sandw.ki$confint)
colnames(sandw.ki.df) <- c("Value", "Lower bound", "Upper bound")
rownames(sandw.ki.df) <- paste(rownames(sandw.ki.df),symb,"0")


sandw.ki.df$sig <- NA
for (i in 1:nrow(sandw.ki.df)) {
  if(sign(sandw.ki.df$'Lower bound')[i]==sign(sandw.ki.df$'Upper bound')[i]){
    sandw.ki.df[i,]$sig <- paste0("The interval (", round(sandw.ki.df$'Lower bound'[i],2), ", ", round(sandw.ki.df$'Upper bound'[i],2), ") traps the true difference ", lev[i+1], "-", factorlevel, " with probability 95 percent.", footnote_marker_number(1, "latex") )
  }else{ 
    sandw.ki.df[i,]$sig <- paste0("The interval (", round(sandw.ki.df$'Lower bound'[i],2), ", ", round(sandw.ki.df$'Upper bound'[i],2), ") traps the true difference ", lev[i+1], "-", factorlevel, " with probability 95 percent.", footnote_marker_number(2, "latex"))}
}
fn4 <- "Remark: Zero is not in the confidence interval."
fn5 <- "Remark: Zero is in the confidence interval."
number_2= c(fn4, fn5)
colnames(sandw.ki.df)[4] <- "Interpretation"
sandw.ki.df <- rownames_to_column(sandw.ki.df, var="Null Hypothesis") %>% head

cat("\\begin{center} Simultaneous Confidence Intervals: Dunnett Contrasts Sandwich \\end{center}", fill=TRUE)
cat(paste0("Simultaneous Confidence Intervals which includes the true value of the difference between the reference level ", factorlevel, " and the other levels of ", key, "."), fill=TRUE)


x2 <- knitr::kable(sandw.ki.df , digits=2, escape = F, linesep = '', caption=cat(" ", fill=TRUE), longtable = T)
footnote(x2, number = number_2) %>% 
  kable_styling(x2, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header")) 

```


\pagebreak 


```{r DunnetStepdownSandwich, dev= "cairo_pdf", eval = eval_model4, results='asis'}
cat("\n## Dunnet Sandwich Step-Down  \n", fill=TRUE)
cat("Note: The step-down procedure may lead to more powerful hypotheses tests and may be be applied for hypotheses satisfying the free combination condition, as in our many-to-one case. ", fill=TRUE)
# MCPs with a control Dunnet step-down, Sandwich
## Construct input to mcp2 function which is an update of the original mcp function 
key <- modelsplit[2] 
factorlevel <- modelsplit [3]
lev <- levels(df_factorized[,colnames(df_factorized)==key])
side <- modelsplit[4]
if(side=="less"){symb <- ">="}
if(side=="greater"){symb <- "<="}
if(side=="two.sided"){symb <- "="}
#Description above
cat("\\begin{center} Multiple Comparison: Dunnet Contrasts step-down Sandwich \\end{center}", fill=TRUE)
if(side == "two.sided"){
  cat(paste("Test whether the factor level ", factorlevel, " of the factor ", key, " is different from the other levels. The Null Hypothesis is for example ", lev[2],"-",factorlevel,"=0."))  
}else{
  cat(paste("Test whether the factor level ", factorlevel, " of the factor ", key, " is ", side, " than the other levels. The Null Hypothesis is for example ", lev[2],"-",factorlevel,symb,"0." ), fill=TRUE)
}

#compute mcp
mylist <- list()
mylist[[key]] <- "Dunnet"
names(mylist) <- key
cat("\\small ", fill=TRUE)
output_sw_sd <- glht(lmfit, linfct = mcp2(mylist), alternative = side, vcov = sandwich)
sum_sw_sd <- summary(output_sw_sd, test = adjusted(type = "free"))
#pretty table
dunnet_sw_sd <- data.frame("Value"=sum_sw_sd$test$coefficients, 
                          "Std.Error"= sum_sw_sd$test$sigma, "T-value"=sum_sw_sd$test$tstat,
                          "P.value"= as.numeric(sum_sw_sd$test$pvalues))
rownames(dunnet_sw_sd) <- paste(rownames(dunnet_sw_sd),symb,"0")
dunnet_sw_sd$'Sign. level' <- NA
dunnet_sw_sd$'Sign. level'[which(abs(dunnet_sw_sd$P.value ) <= 0.001)] <- "***"
dunnet_sw_sd$'Sign. level'[which(abs(dunnet_sw_sd$P.value) > 0.001)] <- "**"
dunnet_sw_sd$'Sign. level'[which(abs(dunnet_sw_sd$P.value) > 0.01)] <- "*"
dunnet_sw_sd$'Sign. level'[which(abs(dunnet_sw_sd$P.value) > 0.05)] <- "."
dunnet_sw_sd$'Sign. level'[which(abs(dunnet_sw_sd$P.value) > 0.1)] <- " "
dunnet_sw_sd$'Sign. level'[which(is.na(dunnet_sw_sd$P.value))] <- "-"
dunnet_sw_sd$P.value <- sapply(dunnet_sw_sd$P.value,pformat)
names(dunnet_sw_sd)[5] <- paste0(names(dunnet_sw_sd)[5], footnote_marker_number(1, "latex"))

#Interpretation
dunnet_sw_sd$sig <- NA
for (i in 1:nrow(dunnet_sw_sd)) {
  if(dunnet_sw_sd[i,]$P.value <= 0.05){
    dunnet_sw_sd[i,]$sig <- paste0("Significant. Level ", lev[i+1], " of factor ", key, " is significantly ", sidetext, " than ", factorlevel, footnote_marker_number(3, "latex"))
  }else{ 
    dunnet_sw_sd[i,]$sig <- paste0("Not Significant. Level ", factorlevel, " of factor ", key , " is not ", sidetext, " than " , lev[i+1], footnote_marker_number(2, "latex"))}
}
# footnote significance codes
names(dunnet_sw_sd)[6] <- "Significance at 5 percent Type I error"
fn1 <- "'***': sign. to 0.1% error. '**': sign. to 1% error. '*': sign. to 5% error. ' . ': sign. to 10% error. '     ': not sign. ' - ': no statement."
fn2 <- "H1 does not hold significantly."
fn3 <-  "H1 holds significantly."
number= c(fn1, fn2, fn3)
#rownames to column 
dunnet_sw_sd <- rownames_to_column(dunnet_sw_sd, var="Null Hypothesis") %>% head
#Output table
opts <- options(knitr.kable.NA = "")
x <- knitr::kable(dunnet_sw_sd, digits=3, escape = F, linesep = '', caption=cat(" ", fill=TRUE), longtable = T)
footnote(x, number = number) %>%
  kable_styling(x, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))
```


```{r references, results="asis"}
cat("# References", fill=TRUE)
```
 
---
nocite: '@*'
...
 